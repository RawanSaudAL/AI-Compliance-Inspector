{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***AI-Compliance-Inspector: Automated Compliance Verification using RAG and LLaVA Author: Rawan Alahmadi***"
      ],
      "metadata": {
        "id": "t2Yf7tHc2oyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Section 1: Downloads - Libraries and Model***"
      ],
      "metadata": {
        "id": "uxtan_Ct2IdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch transformers faiss-cpu pytesseract pdfplumber Pillow llama-index\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex, LLMPredictor, PromptHelper\n",
        "import pytesseract\n",
        "import pdfplumber\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Download and load the LLaVA model\n",
        "model_name = \"LLaVA/llava-7b\"\n",
        "try:\n",
        "    llava_pipeline = pipeline(\"image-to-text\", model=model_name)\n",
        "    print(\"LLaVA model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading LLaVA model: {e}\")\n",
        "\n",
        "print(\"Libraries and model downloaded successfully.\")"
      ],
      "metadata": {
        "id": "Zd-9_8QE2Fav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Section 2: Data Purpose - Preparing Data***"
      ],
      "metadata": {
        "id": "l1oRwLfV2Y7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_text_from_image(image_path):\n",
        "    \"\"\"\n",
        "    Extract text from images using OCR.\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "    Returns:\n",
        "        str: Extracted text from the image.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        text = pytesseract.image_to_string(img, lang=\"eng+ara\")\n",
        "        print(f\"Text extracted from image: {image_path}\")\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from image: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text from PDF files using PDFPlumber.\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file.\n",
        "    Returns:\n",
        "        str: Extracted text from the PDF.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "        print(f\"Text extracted from PDF: {pdf_path}\")\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def describe_image_with_llava(image_path):\n",
        "    \"\"\"\n",
        "    Describe the content of an image using the LLaVA model.\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "    Returns:\n",
        "        str: Description of the image.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        description = llava_pipeline(img)[0]['generated_text']\n",
        "        print(f\"Description generated for image: {image_path}\")\n",
        "        return description\n",
        "    except Exception as e:\n",
        "        print(f\"Error describing image: {e}\")\n",
        "        return \"Unable to describe the image.\"\n",
        "\n",
        "def prepare_data(input_path):\n",
        "    \"\"\"\n",
        "    Prepare data by extracting text from images and PDF files.\n",
        "    Args:\n",
        "        input_path (str): Path to the folder containing documents.\n",
        "    Returns:\n",
        "        dict: Dictionary with filenames as keys and extracted texts as values.\n",
        "    \"\"\"\n",
        "    data = {}\n",
        "    for file_name in os.listdir(input_path):\n",
        "        file_path = os.path.join(input_path, file_name)\n",
        "        if file_name.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            data[file_name] = extract_text_from_image(file_path)\n",
        "        elif file_name.lower().endswith(\".pdf\"):\n",
        "            data[file_name] = extract_text_from_pdf(file_path)\n",
        "        else:\n",
        "            print(f\"Unsupported file format: {file_name}\")\n",
        "    return data"
      ],
      "metadata": {
        "id": "3u_MakEX2ffu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Section 3: RAG Setup - Adding Compliance Files***"
      ],
      "metadata": {
        "id": "tQD3foxX2i1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex, LLMPredictor, PromptHelper\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "def load_compliance_files(compliance_dir):\n",
        "    \"\"\"\n",
        "    Load compliance documents from a specified directory.\n",
        "    Args:\n",
        "        compliance_dir (str): Path to the compliance files directory.\n",
        "    Returns:\n",
        "        dict: Dictionary of compliance texts indexed by file name.\n",
        "    \"\"\"\n",
        "    compliance_data = {}\n",
        "    try:\n",
        "        for file_name in os.listdir(compliance_dir):\n",
        "            file_path = os.path.join(compliance_dir, file_name)\n",
        "            if file_name.lower().endswith((\".txt\", \".pdf\")):\n",
        "                if file_name.lower().endswith(\".pdf\"):\n",
        "                    compliance_text = extract_text_from_pdf(file_path)\n",
        "                else:\n",
        "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                        compliance_text = file.read()\n",
        "                compliance_data[file_name] = compliance_text\n",
        "                print(f\"Loaded compliance file: {file_name}\")\n",
        "            else:\n",
        "                print(f\"Skipping unsupported file format: {file_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading compliance files: {e}\")\n",
        "    return compliance_data\n",
        "\n",
        "def create_rag_index(compliance_data):\n",
        "    \"\"\"\n",
        "    Create a RAG index for compliance documents using Allam model from SDAIA.\n",
        "    Args:\n",
        "        compliance_data (dict): Dictionary of compliance texts.\n",
        "    Returns:\n",
        "        GPTVectorStoreIndex: Index object for RAG.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load Allam model from SDAIA\n",
        "        model_name = \"SDAIA/Allam-7B-Instruct\"\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "        llm_predictor = LLMPredictor(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            temperature=0.5,\n",
        "            max_length=256\n",
        "        )\n",
        "\n",
        "        prompt_helper = PromptHelper(max_input_size=1024, num_output=256, max_chunk_overlap=20)\n",
        "\n",
        "        # Create RAG index using Allam model\n",
        "        documents = [SimpleDirectoryReader(compliance_data).load_data()]\n",
        "        index = GPTVectorStoreIndex.from_documents(\n",
        "            documents,\n",
        "            llm_predictor=llm_predictor,\n",
        "            prompt_helper=prompt_helper\n",
        "        )\n",
        "        print(\"RAG index created successfully using Allam model.\")\n",
        "        return index\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating RAG index with Allam model: {e}\")\n",
        "        return None\n",
        "\n",
        "def search_compliance(query, index):\n",
        "    \"\"\"\n",
        "    Search compliance documents using RAG.\n",
        "    Args:\n",
        "        query (str): User query for compliance check.\n",
        "        index (GPTVectorStoreIndex): The RAG index object.\n",
        "    Returns:\n",
        "        str: The most relevant compliance text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = index.query(query)\n",
        "        print(\"Compliance search completed.\")\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Error during compliance search: {e}\")\n",
        "        return \"No relevant compliance found.\"\n",
        "\n",
        "# Example usage\n",
        "compliance_files_path = \"./compliance_files\"\n",
        "compliance_data = load_compliance_files(compliance_files_path)\n",
        "rag_index = create_rag_index(compliance_data)\n",
        "\n",
        "# Test RAG search with Allam model\n",
        "query = \"What are the data privacy requirements?\"\n",
        "if rag_index:\n",
        "    result = search_compliance(query, rag_index)\n",
        "    print(f\"Search Result: {result}\")"
      ],
      "metadata": {
        "id": "8-IFCFOu2iSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Section 4: Compliance Calculation using SDAIA Allam Model***\n"
      ],
      "metadata": {
        "id": "7pVI9Iww3EPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_compliance(query, index):\n",
        "    \"\"\"\n",
        "    Calculate the compliance score using the RAG model with Allam.\n",
        "    Args:\n",
        "        query (str): The compliance check query.\n",
        "        index (GPTVectorStoreIndex): The RAG index object.\n",
        "    Returns:\n",
        "        dict: Compliance score and relevant information.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Perform RAG-based search using Allam model\n",
        "        result = search_compliance(query, index)\n",
        "\n",
        "        # Example keywords for compliance classification\n",
        "        compliance_keywords = {\n",
        "            \"fully compliant\": 100,\n",
        "            \"compliant\": 90,\n",
        "            \"partially compliant\": 70,\n",
        "            \"non-compliant\": 30,\n",
        "            \"not compliant\": 10,\n",
        "            \"unknown\": 50\n",
        "        }\n",
        "\n",
        "        # Calculate compliance score\n",
        "        compliance_score = 50  # Default for ambiguous cases\n",
        "        for keyword, score in compliance_keywords.items():\n",
        "            if keyword in result.lower():\n",
        "                compliance_score = score\n",
        "                break\n",
        "\n",
        "        # Compile compliance result\n",
        "        compliance_result = {\n",
        "            \"query\": query,\n",
        "            \"result\": result,\n",
        "            \"score\": compliance_score,\n",
        "            \"status\": \"Compliant\" if compliance_score >= 90 else \"Non-Compliant\" if compliance_score <= 30 else \"Partially Compliant\"\n",
        "        }\n",
        "\n",
        "        # Print and return the compliance result\n",
        "        print(f\"\\nCompliance Check: {query}\")\n",
        "        print(f\"Result: {result}\")\n",
        "        print(f\"Compliance Score: {compliance_score}%\")\n",
        "        print(f\"Status: {compliance_result['status']}\\n\")\n",
        "        return compliance_result\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating compliance: {e}\")\n",
        "        return {\"query\": query, \"result\": \"Error\", \"score\": 0, \"status\": \"Unknown\"}\n",
        "\n",
        "# Example usage\n",
        "user_query = \"Does the document comply with data protection regulations?\"\n",
        "if rag_index:\n",
        "    compliance_result = calculate_compliance(user_query, rag_index)\n",
        "    print(f\"Final Compliance Result: {compliance_result}\")\n"
      ],
      "metadata": {
        "id": "IrGxBnU53Dx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Section 5: User Interface for Compliance Check***"
      ],
      "metadata": {
        "id": "p0DapSuq3v2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to interact with the user for compliance checks.\n",
        "    \"\"\"\n",
        "    print(\"\\nWelcome to AI-Compliance-Inspector\")\n",
        "    print(\"Automated Compliance Verification using RAG and Allam Model\\n\")\n",
        "\n",
        "    # Load compliance files and create RAG index\n",
        "    compliance_files_path = \"./compliance_files\"\n",
        "    compliance_data = load_compliance_files(compliance_files_path)\n",
        "    rag_index = create_rag_index(compliance_data)\n",
        "\n",
        "    if rag_index:\n",
        "        while True:\n",
        "            print(\"\\nEnter your compliance query (or type 'exit' to quit):\")\n",
        "            user_query = input(\"> \")\n",
        "\n",
        "            if user_query.lower() == 'exit':\n",
        "                print(\"Exiting the compliance inspector. Goodbye!\")\n",
        "                break\n",
        "\n",
        "            # Calculate compliance\n",
        "            compliance_result = calculate_compliance(user_query, rag_index)\n",
        "\n",
        "            # Display result\n",
        "            print(\"\\n----- Compliance Check Result -----\")\n",
        "            print(f\"Query: {compliance_result['query']}\")\n",
        "            print(f\"Result: {compliance_result['result']}\")\n",
        "            print(f\"Compliance Score: {compliance_result['score']}%\")\n",
        "            print(f\"Status: {compliance_result['status']}\")\n",
        "            print(\"-----------------------------------\\n\")\n",
        "    else:\n",
        "        print(\"Failed to create RAG index. Please check your files and try again.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "pkVT1OJA3wJn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}